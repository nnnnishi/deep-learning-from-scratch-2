{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 リカレントニューラルネットワーク（RNN）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 確率と言語モデル\n",
    "1. RNNとは\n",
    "1. RNNの実装\n",
    "1. word2vecに関する残りのテーマ\n",
    "1. まとめ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.dot(h_prev.T, dt)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, Wx.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeRNNレイヤの実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLMの実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLMの学習コード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocabulary size: 418\n",
      "| epoch 1 | perplexity 393.89\n",
      "| epoch 2 | perplexity 265.79\n",
      "| epoch 3 | perplexity 225.83\n",
      "| epoch 4 | perplexity 217.13\n",
      "| epoch 5 | perplexity 207.51\n",
      "| epoch 6 | perplexity 203.16\n",
      "| epoch 7 | perplexity 199.41\n",
      "| epoch 8 | perplexity 197.41\n",
      "| epoch 9 | perplexity 191.27\n",
      "| epoch 10 | perplexity 192.83\n",
      "| epoch 11 | perplexity 189.67\n",
      "| epoch 12 | perplexity 192.38\n",
      "| epoch 13 | perplexity 189.60\n",
      "| epoch 14 | perplexity 189.64\n",
      "| epoch 15 | perplexity 189.69\n",
      "| epoch 16 | perplexity 186.12\n",
      "| epoch 17 | perplexity 184.08\n",
      "| epoch 18 | perplexity 181.91\n",
      "| epoch 19 | perplexity 183.50\n",
      "| epoch 20 | perplexity 183.72\n",
      "| epoch 21 | perplexity 180.59\n",
      "| epoch 22 | perplexity 180.37\n",
      "| epoch 23 | perplexity 176.74\n",
      "| epoch 24 | perplexity 176.75\n",
      "| epoch 25 | perplexity 175.81\n",
      "| epoch 26 | perplexity 175.09\n",
      "| epoch 27 | perplexity 171.05\n",
      "| epoch 28 | perplexity 169.63\n",
      "| epoch 29 | perplexity 169.92\n",
      "| epoch 30 | perplexity 164.84\n",
      "| epoch 31 | perplexity 163.94\n",
      "| epoch 32 | perplexity 160.27\n",
      "| epoch 33 | perplexity 160.27\n",
      "| epoch 34 | perplexity 155.97\n",
      "| epoch 35 | perplexity 154.56\n",
      "| epoch 36 | perplexity 149.53\n",
      "| epoch 37 | perplexity 143.82\n",
      "| epoch 38 | perplexity 140.08\n",
      "| epoch 39 | perplexity 135.38\n",
      "| epoch 40 | perplexity 132.45\n",
      "| epoch 41 | perplexity 130.00\n",
      "| epoch 42 | perplexity 126.68\n",
      "| epoch 43 | perplexity 118.70\n",
      "| epoch 44 | perplexity 115.52\n",
      "| epoch 45 | perplexity 112.77\n",
      "| epoch 46 | perplexity 108.82\n",
      "| epoch 47 | perplexity 102.99\n",
      "| epoch 48 | perplexity 99.17\n",
      "| epoch 49 | perplexity 96.93\n",
      "| epoch 50 | perplexity 92.70\n",
      "| epoch 51 | perplexity 89.17\n",
      "| epoch 52 | perplexity 83.53\n",
      "| epoch 53 | perplexity 79.07\n",
      "| epoch 54 | perplexity 77.68\n",
      "| epoch 55 | perplexity 73.08\n",
      "| epoch 56 | perplexity 66.28\n",
      "| epoch 57 | perplexity 64.94\n",
      "| epoch 58 | perplexity 61.80\n",
      "| epoch 59 | perplexity 58.44\n",
      "| epoch 60 | perplexity 54.23\n",
      "| epoch 61 | perplexity 52.57\n",
      "| epoch 62 | perplexity 49.86\n",
      "| epoch 63 | perplexity 45.82\n",
      "| epoch 64 | perplexity 43.57\n",
      "| epoch 65 | perplexity 42.75\n",
      "| epoch 66 | perplexity 39.41\n",
      "| epoch 67 | perplexity 37.93\n",
      "| epoch 68 | perplexity 34.82\n",
      "| epoch 69 | perplexity 33.39\n",
      "| epoch 70 | perplexity 31.82\n",
      "| epoch 71 | perplexity 30.38\n",
      "| epoch 72 | perplexity 27.24\n",
      "| epoch 73 | perplexity 25.61\n",
      "| epoch 74 | perplexity 24.67\n",
      "| epoch 75 | perplexity 23.53\n",
      "| epoch 76 | perplexity 22.40\n",
      "| epoch 77 | perplexity 21.05\n",
      "| epoch 78 | perplexity 18.97\n",
      "| epoch 79 | perplexity 17.87\n",
      "| epoch 80 | perplexity 17.44\n",
      "| epoch 81 | perplexity 16.86\n",
      "| epoch 82 | perplexity 15.92\n",
      "| epoch 83 | perplexity 14.64\n",
      "| epoch 84 | perplexity 14.38\n",
      "| epoch 85 | perplexity 13.18\n",
      "| epoch 86 | perplexity 12.77\n",
      "| epoch 87 | perplexity 11.96\n",
      "| epoch 88 | perplexity 11.18\n",
      "| epoch 89 | perplexity 10.65\n",
      "| epoch 90 | perplexity 10.45\n",
      "| epoch 91 | perplexity 10.03\n",
      "| epoch 92 | perplexity 9.14\n",
      "| epoch 93 | perplexity 8.68\n",
      "| epoch 94 | perplexity 8.48\n",
      "| epoch 95 | perplexity 8.64\n",
      "| epoch 96 | perplexity 8.02\n",
      "| epoch 97 | perplexity 7.03\n",
      "| epoch 98 | perplexity 6.46\n",
      "| epoch 99 | perplexity 6.34\n",
      "| epoch 100 | perplexity 6.15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117e7be48>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5  # Truncated BPTTの展開する時間サイズ\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 学習データの読み込み（データセットを小さくする）\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "data_size = len(xs)\n",
    "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 学習時に使用する変数\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# モデルの生成\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# ミニバッチの各サンプルの読み込み開始位置を計算\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLMの\bTrainerクラス\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from common.np import *  # import numpy as np\n",
    "from common.util import clip_grads\n",
    "\n",
    "\n",
    "class RnnlmTrainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.time_idx = None\n",
    "        self.ppl_list = None\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]  # バッチの各サンプルの読み込み開始位置\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "\n",
    "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\n",
    "            max_grad=None, eval_interval=20):\n",
    "        data_size = len(xs)\n",
    "        max_iters = data_size // (batch_size * time_size)\n",
    "        self.time_idx = 0\n",
    "        self.ppl_list = []\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            for iters in range(max_iters):\n",
    "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "                # 勾配を求め、パラメータを更新\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # パープレキシティの評価\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    ppl = np.exp(total_loss / loss_count)\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| epoch %d |  iter %d / %d | time %d[s] | perplexity %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\n",
    "                    self.ppl_list.append(float(ppl))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.ppl_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.ppl_list, label='train')\n",
    "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('perplexity')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def remove_duplicate(params, grads):\n",
    "    '''\n",
    "    パラメータ配列中の重複する重みをひとつに集約し、\n",
    "    その重みに対応する勾配を加算する\n",
    "    '''\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 重みを共有する場合\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 勾配の加算\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 転置行列として重みを共有する場合（weight tying）\n",
    "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
    "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg: break\n",
    "            if find_flg: break\n",
    "\n",
    "        if not find_flg: break\n",
    "\n",
    "    return params, grads"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.1.1]",
   "language": "python",
   "name": "conda-env-anaconda3-4.1.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipythonP",
  "version": "Python 3.5.2 :: Anaconda custom (x86_64)"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
